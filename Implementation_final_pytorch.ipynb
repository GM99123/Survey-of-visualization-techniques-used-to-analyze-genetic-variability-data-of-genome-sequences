{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math,copy\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(21, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1130,  0.2931, -0.9396, -0.2664,  0.0778],\n",
       "        [-1.1823, -0.7777, -0.6811,  0.4352, -0.4074]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq_enz_data_split_500.npy', 'rb') as f:\n",
    "    a = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seq_non_enz_data_split_500.npy', 'rb') as f:\n",
    "    b = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(list(a)+list(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = list(pd.Series(a[0]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = []\n",
    "for i in data:\n",
    "    tem = []\n",
    "    for j in range(data.shape[1]):\n",
    "        try:\n",
    "            tem.append( dict_.index(i[j]) )\n",
    "        except:\n",
    "            tem.append(0)\n",
    "    encoded_data.append(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = list(np.zeros((600,1),dtype=int))+list(np.ones((599,1),dtype=int))  #+list(np.zeros_like(b,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_t = []\n",
    "for i in target:\n",
    "    if i[0] == 0:\n",
    "        target_t.append([1,0])\n",
    "    else:\n",
    "        target_t.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_t[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data = []\n",
    "for i in encoded_data:\n",
    "    embed_data.append(embed(torch.tensor(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2214, -0.4445,  0.6064,  1.6632, -0.2181],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embed_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22136997, -0.44450822,  0.6064224 ,  1.6631844 , -0.21809869],\n",
       "       [ 1.1129605 ,  0.29309446, -0.939614  , -0.26642385,  0.0778375 ],\n",
       "       [-1.1823006 , -0.7777363 , -0.6810685 ,  0.4352491 , -0.40738904],\n",
       "       ...,\n",
       "       [-0.03570509,  0.60774314,  0.0155361 ,  0.03611943,  0.12822247],\n",
       "       [-0.03570509,  0.60774314,  0.0155361 ,  0.03611943,  0.12822247],\n",
       "       [-0.03570509,  0.60774314,  0.0155361 ,  0.03611943,  0.12822247]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_data[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data_batch = []\n",
    "for X in embed_data:\n",
    "    embed_data_batch.append( np.array(np.array(X.detach().numpy()).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 5, 500)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embed_data_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (conv1): Conv1d(5, 200, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(200, 100, kernel_size=(3,), stride=(1,))\n",
      "  (fc1): Linear(in_features=49600, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (soft): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(5,200,3)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(200, 100, 3)\n",
    "        self.fc1 = nn.Linear(100 * 496 , 20)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.soft(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 5],\n",
       "       [1, 3, 6]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed_data[0].transpose((1, 0))\n",
    "np.array([[0,1],\n",
    "         [2,3],\n",
    "         [5,6]]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(embed_data,target_ten, model, loss_fn, optimizer):\n",
    "    n = 0\n",
    "    model.train()\n",
    "    loss_t = 0\n",
    "    X,y = embed_data,target_ten\n",
    "#     for X, y in zip(embed_data,target_ten):\n",
    "#         X, y = torch.tensor(np.array([np.array(X.detach().numpy()).transpose()])).to(device), torch.tensor(np.array([y])).to(device)\n",
    "    X, y = torch.tensor(X).to(device), torch.tensor(np.array(y)).to(device)\n",
    "    y = y.float()\n",
    "    X = X.float()\n",
    "#         print(X.shape)\n",
    "    pred = model(X)\n",
    "    if n == 0:\n",
    "#         print(pred.shape,pred)\n",
    "#         print(y.shape,y)\n",
    "        n += 1\n",
    "    loss = loss_fn(pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()\n",
    "#         print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    loss_t += loss\n",
    "    print(loss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4927, 0.5073],\n",
      "        [0.4872, 0.5128],\n",
      "        [0.5087, 0.4913],\n",
      "        ...,\n",
      "        [0.5002, 0.4998],\n",
      "        [0.4891, 0.5109],\n",
      "        [0.4956, 0.5044]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6931829452514648\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.7625, 0.2375],\n",
      "        [0.7854, 0.2146],\n",
      "        [0.7637, 0.2363],\n",
      "        ...,\n",
      "        [0.6215, 0.3785],\n",
      "        [0.6196, 0.3804],\n",
      "        [0.6517, 0.3483]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6965106725692749\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.2562, 0.7438],\n",
      "        [0.2411, 0.7589],\n",
      "        [0.2661, 0.7339],\n",
      "        ...,\n",
      "        [0.2810, 0.7190],\n",
      "        [0.2782, 0.7218],\n",
      "        [0.2767, 0.7233]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.7257713675498962\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4963, 0.5037],\n",
      "        [0.4963, 0.5037],\n",
      "        [0.4964, 0.5036],\n",
      "        ...,\n",
      "        [0.4536, 0.5464],\n",
      "        [0.4547, 0.5453],\n",
      "        [0.4669, 0.5331]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6881265640258789\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4648, 0.5352],\n",
      "        [0.4646, 0.5354],\n",
      "        [0.4715, 0.5285],\n",
      "        ...,\n",
      "        [0.3965, 0.6035],\n",
      "        [0.3966, 0.6034],\n",
      "        [0.4099, 0.5901]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.685013473033905\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4969, 0.5031],\n",
      "        [0.4971, 0.5029],\n",
      "        [0.4974, 0.5026],\n",
      "        ...,\n",
      "        [0.4213, 0.5787],\n",
      "        [0.4216, 0.5784],\n",
      "        [0.4475, 0.5525]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6839392185211182\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4750, 0.5250],\n",
      "        [0.4874, 0.5126],\n",
      "        [0.4828, 0.5172],\n",
      "        ...,\n",
      "        [0.3217, 0.6783],\n",
      "        [0.3208, 0.6792],\n",
      "        [0.3473, 0.6527]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6783717274665833\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4982, 0.5018],\n",
      "        [0.4995, 0.5005],\n",
      "        [0.4983, 0.5017],\n",
      "        ...,\n",
      "        [0.3157, 0.6843],\n",
      "        [0.3146, 0.6854],\n",
      "        [0.3521, 0.6479]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6745827198028564\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4554, 0.5446],\n",
      "        [0.4733, 0.5267],\n",
      "        [0.4653, 0.5347],\n",
      "        ...,\n",
      "        [0.2131, 0.7869],\n",
      "        [0.2116, 0.7884],\n",
      "        [0.2515, 0.7485]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6726430654525757\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.5130, 0.4870],\n",
      "        [0.5122, 0.4878],\n",
      "        [0.5136, 0.4864],\n",
      "        ...,\n",
      "        [0.3591, 0.6409],\n",
      "        [0.3556, 0.6444],\n",
      "        [0.4224, 0.5776]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6738522052764893\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4352, 0.5648],\n",
      "        [0.4503, 0.5497],\n",
      "        [0.4484, 0.5516],\n",
      "        ...,\n",
      "        [0.1406, 0.8594],\n",
      "        [0.1355, 0.8645],\n",
      "        [0.1783, 0.8217]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6750719547271729\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.5655, 0.4345],\n",
      "        [0.5644, 0.4356],\n",
      "        [0.5657, 0.4343],\n",
      "        ...,\n",
      "        [0.3809, 0.6191],\n",
      "        [0.3807, 0.6193],\n",
      "        [0.4593, 0.5407]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6702579855918884\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.5891, 0.4109],\n",
      "        [0.5881, 0.4119],\n",
      "        [0.5900, 0.4100],\n",
      "        ...,\n",
      "        [0.2012, 0.7988],\n",
      "        [0.1955, 0.8045],\n",
      "        [0.2732, 0.7268]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6551223397254944\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6360, 0.3640],\n",
      "        [0.6421, 0.3579],\n",
      "        [0.6525, 0.3475],\n",
      "        ...,\n",
      "        [0.1689, 0.8311],\n",
      "        [0.1645, 0.8355],\n",
      "        [0.2495, 0.7505]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6478049159049988\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.7213, 0.2787],\n",
      "        [0.7146, 0.2854],\n",
      "        [0.7228, 0.2772],\n",
      "        ...,\n",
      "        [0.2045, 0.7955],\n",
      "        [0.2022, 0.7978],\n",
      "        [0.3211, 0.6789]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.64327472448349\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4847, 0.5153],\n",
      "        [0.4861, 0.5139],\n",
      "        [0.5165, 0.4835],\n",
      "        ...,\n",
      "        [0.0594, 0.9406],\n",
      "        [0.0579, 0.9421],\n",
      "        [0.1058, 0.8942]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6571863293647766\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.8763, 0.1237],\n",
      "        [0.8702, 0.1298],\n",
      "        [0.8758, 0.1242],\n",
      "        ...,\n",
      "        [0.6647, 0.3353],\n",
      "        [0.6771, 0.3229],\n",
      "        [0.7942, 0.2058]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.7115520238876343\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6160, 0.3840],\n",
      "        [0.6029, 0.3971],\n",
      "        [0.6251, 0.3749],\n",
      "        ...,\n",
      "        [0.2189, 0.7811],\n",
      "        [0.2041, 0.7959],\n",
      "        [0.3375, 0.6625]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.647232711315155\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6573, 0.3427],\n",
      "        [0.6414, 0.3586],\n",
      "        [0.6691, 0.3309],\n",
      "        ...,\n",
      "        [0.1032, 0.8968],\n",
      "        [0.0905, 0.9095],\n",
      "        [0.1825, 0.8175]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6369794607162476\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.7198, 0.2802],\n",
      "        [0.6879, 0.3121],\n",
      "        [0.7318, 0.2682],\n",
      "        ...,\n",
      "        [0.1250, 0.8750],\n",
      "        [0.1130, 0.8870],\n",
      "        [0.2343, 0.7657]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6292114853858948\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(embed_data_batch,target_t, model, loss_fn, optimizer)\n",
    "    #test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(embed_data,target_ten, model, loss_fn, optimizer):\n",
    "    n = 0\n",
    "    model.eval()\n",
    "    loss_t = 0\n",
    "    X,y = embed_data,target_ten\n",
    "#     for X, y in zip(embed_data,target_ten):\n",
    "#         X, y = torch.tensor(np.array([np.array(X.detach().numpy()).transpose()])).to(device), torch.tensor(np.array([y])).to(device)\n",
    "    X, y = torch.tensor(X).to(device), torch.tensor(np.array(y)).to(device)\n",
    "    y = y.float()\n",
    "    X = X.float()\n",
    "#         print(X.shape)\n",
    "    pred = model(X)\n",
    "    if n == 0:\n",
    "        print(pred.shape,pred)\n",
    "        print(y.shape,y)\n",
    "        n += 1\n",
    "    loss = loss_fn(pred, y)\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    loss = loss.item()\n",
    "#         print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    loss_t += loss\n",
    "    print(loss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6480, 0.3520],\n",
      "        [0.5847, 0.4153],\n",
      "        [0.7042, 0.2958],\n",
      "        ...,\n",
      "        [0.0826, 0.9174],\n",
      "        [0.0742, 0.9258],\n",
      "        [0.1667, 0.8333]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6218894720077515\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    test(embed_data_batch,target_t, model, loss_fn, optimizer)\n",
    "    #test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4472, 0.5528],\n",
      "        [0.4582, 0.5418],\n",
      "        [0.4454, 0.5546],\n",
      "        ...,\n",
      "        [0.4407, 0.5593],\n",
      "        [0.4348, 0.5652],\n",
      "        [0.4557, 0.5443]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6943832039833069\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.9937, 0.0063],\n",
      "        [0.9960, 0.0040],\n",
      "        [0.9931, 0.0069],\n",
      "        ...,\n",
      "        [0.9707, 0.0293],\n",
      "        [0.9701, 0.0299],\n",
      "        [0.9788, 0.0212]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.803155779838562\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.7789, 0.2211],\n",
      "        [0.8286, 0.1714],\n",
      "        [0.7756, 0.2244],\n",
      "        ...,\n",
      "        [0.5348, 0.4652],\n",
      "        [0.5336, 0.4664],\n",
      "        [0.5896, 0.4104]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6850662231445312\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4257, 0.5743],\n",
      "        [0.4291, 0.5709],\n",
      "        [0.4247, 0.5753],\n",
      "        ...,\n",
      "        [0.4248, 0.5752],\n",
      "        [0.4248, 0.5752],\n",
      "        [0.4249, 0.5751]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6953031420707703\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4736, 0.5264],\n",
      "        [0.4765, 0.5235],\n",
      "        [0.4667, 0.5333],\n",
      "        ...,\n",
      "        [0.4393, 0.5607],\n",
      "        [0.4391, 0.5609],\n",
      "        [0.4452, 0.5548]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6890332698822021\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.5403, 0.4597],\n",
      "        [0.5480, 0.4520],\n",
      "        [0.5282, 0.4718],\n",
      "        ...,\n",
      "        [0.4615, 0.5385],\n",
      "        [0.4600, 0.5400],\n",
      "        [0.4757, 0.5243]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6816564798355103\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.5972, 0.4028],\n",
      "        [0.6152, 0.3848],\n",
      "        [0.5808, 0.4192],\n",
      "        ...,\n",
      "        [0.4571, 0.5429],\n",
      "        [0.4551, 0.5449],\n",
      "        [0.4828, 0.5172]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6742534637451172\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6371, 0.3629],\n",
      "        [0.6688, 0.3312],\n",
      "        [0.6217, 0.3783],\n",
      "        ...,\n",
      "        [0.4311, 0.5689],\n",
      "        [0.4336, 0.5664],\n",
      "        [0.4693, 0.5307]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6668931245803833\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6872, 0.3128],\n",
      "        [0.7195, 0.2805],\n",
      "        [0.6669, 0.3331],\n",
      "        ...,\n",
      "        [0.3976, 0.6024],\n",
      "        [0.3966, 0.6034],\n",
      "        [0.4386, 0.5614]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6587120890617371\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6497, 0.3503],\n",
      "        [0.6835, 0.3165],\n",
      "        [0.6268, 0.3732],\n",
      "        ...,\n",
      "        [0.3531, 0.6469],\n",
      "        [0.3510, 0.6490],\n",
      "        [0.3698, 0.6302]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6491140723228455\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.8631, 0.1369],\n",
      "        [0.8769, 0.1231],\n",
      "        [0.8415, 0.1585],\n",
      "        ...,\n",
      "        [0.4646, 0.5354],\n",
      "        [0.4562, 0.5438],\n",
      "        [0.5487, 0.4513]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6610492467880249\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.0774, 0.9226],\n",
      "        [0.0893, 0.9107],\n",
      "        [0.0827, 0.9173],\n",
      "        ...,\n",
      "        [0.0571, 0.9429],\n",
      "        [0.0547, 0.9453],\n",
      "        [0.0558, 0.9442]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.7778545618057251\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.3761, 0.6239],\n",
      "        [0.3856, 0.6144],\n",
      "        [0.3788, 0.6212],\n",
      "        ...,\n",
      "        [0.3230, 0.6770],\n",
      "        [0.3128, 0.6872],\n",
      "        [0.3215, 0.6785]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6945984363555908\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4339, 0.5661],\n",
      "        [0.4325, 0.5675],\n",
      "        [0.4305, 0.5695],\n",
      "        ...,\n",
      "        [0.3774, 0.6226],\n",
      "        [0.3707, 0.6293],\n",
      "        [0.3879, 0.6121]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6857525706291199\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.5490, 0.4510],\n",
      "        [0.5599, 0.4401],\n",
      "        [0.5309, 0.4691],\n",
      "        ...,\n",
      "        [0.3504, 0.6496],\n",
      "        [0.3400, 0.6600],\n",
      "        [0.3753, 0.6247]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6617050170898438\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.6450, 0.3550],\n",
      "        [0.6710, 0.3290],\n",
      "        [0.6137, 0.3863],\n",
      "        ...,\n",
      "        [0.2752, 0.7248],\n",
      "        [0.2633, 0.7367],\n",
      "        [0.3260, 0.6740]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6431492567062378\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.7520, 0.2480],\n",
      "        [0.7859, 0.2141],\n",
      "        [0.7151, 0.2849],\n",
      "        ...,\n",
      "        [0.2278, 0.7722],\n",
      "        [0.2165, 0.7835],\n",
      "        [0.3138, 0.6862]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6293699741363525\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.4407, 0.5593],\n",
      "        [0.4614, 0.5386],\n",
      "        [0.4274, 0.5726],\n",
      "        ...,\n",
      "        [0.1084, 0.8916],\n",
      "        [0.0982, 0.9018],\n",
      "        [0.1315, 0.8685]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.6445226073265076\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.9971, 0.0029],\n",
      "        [0.9982, 0.0018],\n",
      "        [0.9952, 0.0048],\n",
      "        ...,\n",
      "        [0.9052, 0.0948],\n",
      "        [0.9228, 0.0772],\n",
      "        [0.9608, 0.0392]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "0.7853976488113403\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "torch.Size([1199, 2]) tensor([[0.9011, 0.0989],\n",
      "        [0.9244, 0.0756],\n",
      "        [0.8803, 0.1197],\n",
      "        ...,\n",
      "        [0.4850, 0.5150],\n",
      "        [0.5194, 0.4806],\n",
      "        [0.6478, 0.3522]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1199, 2]) tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676830530166626\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(embed_data_batch,target_t, model, loss_fn, optimizer)\n",
    "    #test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "0.6929490566253662\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "0.6680653691291809\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "0.8136221766471863\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "0.8136786818504333\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(embed_data_batch,target_t, model, loss_fn, optimizer)\n",
    "    #test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
